{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "HAR_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDUsL4nlzWsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrb1I-xFzWsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO-Qto_6zWsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activities are the class labels\n",
        "# It is a 6 class classification\n",
        "ACTIVITIES = {\n",
        "    0: 'WALKING',\n",
        "    1: 'WALKING_UPSTAIRS',\n",
        "    2: 'WALKING_DOWNSTAIRS',\n",
        "    3: 'SITTING',\n",
        "    4: 'STANDING',\n",
        "    5: 'LAYING',\n",
        "}\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL-_8nEtzWsV",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxqF1uABzWsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI_HAR_Dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeYbgzTDzWsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ash04j9Rn0V",
        "colab_type": "code",
        "outputId": "97a41ad1-9452-494d-d863-8dc2811c3ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnCaXzfkq2jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = 'gdrive/My Drive/UCI_HAR_Dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q5ryMAgzWsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = f'gdrive/My Drive/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKt6NHt_zWsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = f'gdrive/My Drive/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8fxtlwczWsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j-sRDxIzWsn",
        "colab_type": "code",
        "outputId": "39f7f5e4-efd2-43ee-dffb-b531365f73bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "# Importing tensorflow\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKJH-Ix6zWss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuring a session\n",
        "session_conf = tf.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcxPa3MSzWsv",
        "colab_type": "code",
        "outputId": "a1e33130-5b90-41ea-b41a-5100afe4ae56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import Keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12oxCSkzzWsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TUqjEYFzWs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing parameters\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SORNXEzWs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to count the number of classes\n",
        "def _count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nq6QpAwzWtA",
        "colab_type": "code",
        "outputId": "13cf667b-f4ea-42be-ffd9-a51125da82e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT__r0SPzWtD",
        "colab_type": "code",
        "outputId": "01fc69fe-6132-4f4c-9bdd-54b1b784c5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "n_classes = _count_classes(Y_train)\n",
        "\n",
        "print(timesteps)\n",
        "print(input_dim)\n",
        "print(len(X_train))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "9\n",
            "7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlDkKiMhzWtI",
        "colab_type": "text"
      },
      "source": [
        "- Defining the Architecture of LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhtiy9hOzWtK",
        "colab_type": "code",
        "outputId": "9fad1e39-6edf-4827-8b45-d15156c72501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhaJ57zIzWtN",
        "colab_type": "code",
        "outputId": "bd6d1275-97b7-4f5e-b59a-d2b81f4654b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqGwK9fkzWtQ",
        "colab_type": "code",
        "outputId": "c1a0fb13-d56e-4f06-e31b-d69903b06643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the model\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 1.3154 - acc: 0.4361 - val_loss: 1.1414 - val_acc: 0.4761\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.9767 - acc: 0.5830 - val_loss: 0.9244 - val_acc: 0.5996\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.8059 - acc: 0.6413 - val_loss: 0.8358 - val_acc: 0.5931\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.6793 - acc: 0.6658 - val_loss: 0.7258 - val_acc: 0.6118\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.6383 - acc: 0.6798 - val_loss: 0.7400 - val_acc: 0.6250\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5991 - acc: 0.6931 - val_loss: 0.6634 - val_acc: 0.6987\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5830 - acc: 0.7281 - val_loss: 0.6926 - val_acc: 0.7214\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5605 - acc: 0.7542 - val_loss: 0.8642 - val_acc: 0.7034\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4871 - acc: 0.7794 - val_loss: 0.6578 - val_acc: 0.7424\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4631 - acc: 0.7900 - val_loss: 0.5995 - val_acc: 0.7346\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4045 - acc: 0.8104 - val_loss: 0.6348 - val_acc: 0.7384\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.3644 - acc: 0.8360 - val_loss: 0.6054 - val_acc: 0.8140\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.3401 - acc: 0.8757 - val_loss: 0.5558 - val_acc: 0.8575\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2958 - acc: 0.9151 - val_loss: 0.6369 - val_acc: 0.8490\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2888 - acc: 0.9159 - val_loss: 0.5165 - val_acc: 0.8588\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.2988 - acc: 0.9135 - val_loss: 0.4825 - val_acc: 0.8755\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2205 - acc: 0.9331 - val_loss: 0.4576 - val_acc: 0.8870\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.3383 - acc: 0.8955 - val_loss: 0.8236 - val_acc: 0.8317\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2276 - acc: 0.9302 - val_loss: 0.4568 - val_acc: 0.8948\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2050 - acc: 0.9372 - val_loss: 1.1864 - val_acc: 0.7906\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1884 - acc: 0.9400 - val_loss: 0.4367 - val_acc: 0.8907\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1727 - acc: 0.9448 - val_loss: 0.5578 - val_acc: 0.8819\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1943 - acc: 0.9416 - val_loss: 0.4931 - val_acc: 0.8948\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2165 - acc: 0.9359 - val_loss: 0.5253 - val_acc: 0.8921\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1697 - acc: 0.9470 - val_loss: 0.6772 - val_acc: 0.8785\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2266 - acc: 0.9353 - val_loss: 0.4977 - val_acc: 0.9030\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2223 - acc: 0.9338 - val_loss: 0.4627 - val_acc: 0.8643\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2105 - acc: 0.9338 - val_loss: 0.4501 - val_acc: 0.8921\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1874 - acc: 0.9427 - val_loss: 0.5056 - val_acc: 0.8968\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1629 - acc: 0.9478 - val_loss: 0.4753 - val_acc: 0.9040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbdf9d25940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcsW-kDMzWtZ",
        "colab_type": "code",
        "outputId": "69266f48-a0c4-4679-a30c-fb9e8d5b6532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model.predict(X_test)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 509        1  ...                   0                27\n",
            "SITTING                  0      416  ...                   0                 2\n",
            "STANDING                 0      107  ...                   0                 1\n",
            "WALKING                  0        0  ...                  18                10\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 410                 9\n",
            "WALKING_UPSTAIRS         0        1  ...                  18               437\n",
            "\n",
            "[6 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VLl7yXzzWte",
        "colab_type": "code",
        "outputId": "a172d570-acea-43d1-b6a4-5ef5a4dbac3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "score"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2947/2947 [==============================] - 1s 299us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4753849825397535, 0.9039701391245334]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj4yPklDFpIB",
        "colab_type": "text"
      },
      "source": [
        "1 lstm layer + 128 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm1n3rlVzWth",
        "colab_type": "code",
        "outputId": "f7c6306d-3a3c-46d5-9e41-6af398a3e9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(128, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               70656     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 71,430\n",
            "Trainable params: 71,430\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu7lv-uieyQ0",
        "colab_type": "code",
        "outputId": "3c638628-bb94-4401-8c77-b1a298270dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 1.5807 - acc: 0.3094 - val_loss: 1.4886 - val_acc: 0.3332\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 1.3687 - acc: 0.3735 - val_loss: 1.3785 - val_acc: 0.3448\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.3510 - acc: 0.3753 - val_loss: 1.3936 - val_acc: 0.3448\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.3634 - acc: 0.3881 - val_loss: 1.4029 - val_acc: 0.3593\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.3266 - acc: 0.4181 - val_loss: 1.4404 - val_acc: 0.3336\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.3597 - acc: 0.3819 - val_loss: 1.4088 - val_acc: 0.3373\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.2745 - acc: 0.4392 - val_loss: 1.2551 - val_acc: 0.4133\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.3043 - acc: 0.4343 - val_loss: 1.2944 - val_acc: 0.4269\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.9498 - acc: 0.5403 - val_loss: 0.8312 - val_acc: 0.5850\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.7874 - acc: 0.6104 - val_loss: 0.7344 - val_acc: 0.6077\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.6585 - acc: 0.6606 - val_loss: 0.6300 - val_acc: 0.6135\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.6175 - acc: 0.7047 - val_loss: 0.7993 - val_acc: 0.6963\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.5021 - acc: 0.7767 - val_loss: 0.4916 - val_acc: 0.7801\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.4569 - acc: 0.7893 - val_loss: 0.5059 - val_acc: 0.7798\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.5414 - acc: 0.7580 - val_loss: 0.6140 - val_acc: 0.7672\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.4502 - acc: 0.8101 - val_loss: 0.5141 - val_acc: 0.7648\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.3661 - acc: 0.8517 - val_loss: 0.4330 - val_acc: 0.8487\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.3158 - acc: 0.8885 - val_loss: 0.4372 - val_acc: 0.8561\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.5717 - acc: 0.7878 - val_loss: 0.4179 - val_acc: 0.8232\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.4705 - acc: 0.8166 - val_loss: 0.3621 - val_acc: 0.8707\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.3093 - acc: 0.8930 - val_loss: 0.5072 - val_acc: 0.8595\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.2967 - acc: 0.8931 - val_loss: 0.4164 - val_acc: 0.8765\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1973 - acc: 0.9280 - val_loss: 0.4487 - val_acc: 0.8806\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1998 - acc: 0.9263 - val_loss: 0.4173 - val_acc: 0.8853\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.2282 - acc: 0.9180 - val_loss: 0.4512 - val_acc: 0.8792\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1771 - acc: 0.9376 - val_loss: 0.4211 - val_acc: 0.8829\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1855 - acc: 0.9363 - val_loss: 0.3617 - val_acc: 0.8911\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1520 - acc: 0.9421 - val_loss: 0.3661 - val_acc: 0.8816\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1629 - acc: 0.9459 - val_loss: 0.4378 - val_acc: 0.8816\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1526 - acc: 0.9377 - val_loss: 0.4440 - val_acc: 0.8768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc148916fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu07esKxeyXY",
        "colab_type": "code",
        "outputId": "fcc86bae-5461-47fe-9eab-03575aa06760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"===================================================================\")\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 535        1  ...                   0                 1\n",
            "SITTING                  0      305  ...                   0                 0\n",
            "STANDING                 0       34  ...                   0                 0\n",
            "WALKING                  0        0  ...                  39                17\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 398                16\n",
            "WALKING_UPSTAIRS         0        0  ...                  26               409\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 2s 826us/step\n",
            "===================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44404495626493334, 0.8768238887003733]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGUfKMIzFxlN",
        "colab_type": "text"
      },
      "source": [
        "1 hidden lstm layer + 64 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW-ZhsIVdJ95",
        "colab_type": "code",
        "outputId": "201a0bb1-95d7-4599-f4ab-81d403d3db06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(64, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.3))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 64)                18944     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 19,334\n",
            "Trainable params: 19,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpmsOpIefVO3",
        "colab_type": "code",
        "outputId": "8c02f90d-4a8f-43df-f99b-4cf7bbd82c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 37s 5ms/step - loss: 1.3195 - acc: 0.4166 - val_loss: 1.3536 - val_acc: 0.3655\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2865 - acc: 0.4140 - val_loss: 1.2399 - val_acc: 0.4849\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 1.1092 - acc: 0.5133 - val_loss: 1.0629 - val_acc: 0.5273\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 0.9822 - acc: 0.5422 - val_loss: 0.9051 - val_acc: 0.5239\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.9226 - acc: 0.5839 - val_loss: 0.8441 - val_acc: 0.6312\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.7458 - acc: 0.6348 - val_loss: 0.7618 - val_acc: 0.6193\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 0.6800 - acc: 0.6717 - val_loss: 0.7005 - val_acc: 0.6542\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.6475 - acc: 0.6952 - val_loss: 0.6663 - val_acc: 0.7160\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.7164 - acc: 0.6571 - val_loss: 0.7432 - val_acc: 0.6172\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.6326 - acc: 0.7059 - val_loss: 0.6293 - val_acc: 0.7146\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 0.5175 - acc: 0.7678 - val_loss: 0.5829 - val_acc: 0.7299\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.4523 - acc: 0.8394 - val_loss: 0.5013 - val_acc: 0.8405\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.3243 - acc: 0.8898 - val_loss: 0.5267 - val_acc: 0.8395\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.3076 - acc: 0.8980 - val_loss: 1.0603 - val_acc: 0.7771\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 0.2627 - acc: 0.9149 - val_loss: 0.4022 - val_acc: 0.8962\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 33s 5ms/step - loss: 0.2080 - acc: 0.9290 - val_loss: 0.3430 - val_acc: 0.8568\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.2100 - acc: 0.9208 - val_loss: 0.2929 - val_acc: 0.9013\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1562 - acc: 0.9397 - val_loss: 0.2724 - val_acc: 0.8958\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1510 - acc: 0.9436 - val_loss: 0.3032 - val_acc: 0.9111\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.2032 - acc: 0.9280 - val_loss: 0.3471 - val_acc: 0.8761\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1822 - acc: 0.9354 - val_loss: 0.2998 - val_acc: 0.8979\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1326 - acc: 0.9457 - val_loss: 0.3404 - val_acc: 0.8962\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1524 - acc: 0.9445 - val_loss: 0.3368 - val_acc: 0.9009\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1855 - acc: 0.9217 - val_loss: 0.4609 - val_acc: 0.8714\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1660 - acc: 0.9353 - val_loss: 0.2720 - val_acc: 0.9121\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1631 - acc: 0.9353 - val_loss: 0.5130 - val_acc: 0.8897\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1352 - acc: 0.9456 - val_loss: 0.4361 - val_acc: 0.9104\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1498 - acc: 0.9416 - val_loss: 0.3960 - val_acc: 0.8999\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1283 - acc: 0.9501 - val_loss: 0.3987 - val_acc: 0.8965\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1304 - acc: 0.9489 - val_loss: 0.4245 - val_acc: 0.8941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75a83b7940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYZnMxT4gX8m",
        "colab_type": "code",
        "outputId": "c028f668-e21a-4b0c-addd-d69946c39082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"===================================================================\")\n",
        "score"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                 1\n",
            "SITTING                  0      410  ...                   0                 2\n",
            "STANDING                 0       93  ...                   0                 4\n",
            "WALKING                  0        0  ...                   8                 6\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 376                10\n",
            "WALKING_UPSTAIRS         0        0  ...                   0               424\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 1s 448us/step\n",
            "===================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4244747120754469, 0.8941296233457754]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5VOwGCM__na",
        "colab_type": "text"
      },
      "source": [
        "1 hidden layer + 200 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-KVEpn9dKC6",
        "colab_type": "code",
        "outputId": "d11a6477-847b-4cbf-8d48-82b1acfdf494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(200, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 200)               168000    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 1206      \n",
            "=================================================================\n",
            "Total params: 169,206\n",
            "Trainable params: 169,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raBizaFgfWo1",
        "colab_type": "code",
        "outputId": "e16d592a-88dd-41ca-fa25-cec286e06dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 1.2758 - acc: 0.4344 - val_loss: 1.2578 - val_acc: 0.4028\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.9528 - acc: 0.5666 - val_loss: 0.8627 - val_acc: 0.6515\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.7216 - acc: 0.7016 - val_loss: 0.7942 - val_acc: 0.6885\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.4045 - acc: 0.8489 - val_loss: 0.6017 - val_acc: 0.7940\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2637 - acc: 0.9044 - val_loss: 0.3753 - val_acc: 0.8721\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2280 - acc: 0.9169 - val_loss: 0.4190 - val_acc: 0.8792\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2080 - acc: 0.9271 - val_loss: 0.3075 - val_acc: 0.9006\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1866 - acc: 0.9344 - val_loss: 0.5427 - val_acc: 0.8500\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1631 - acc: 0.9389 - val_loss: 0.2900 - val_acc: 0.9097\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1743 - acc: 0.9378 - val_loss: 0.3475 - val_acc: 0.8979\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 87s 12ms/step - loss: 0.1794 - acc: 0.9363 - val_loss: 0.2917 - val_acc: 0.9111\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1527 - acc: 0.9411 - val_loss: 0.2892 - val_acc: 0.9192\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1604 - acc: 0.9429 - val_loss: 0.3926 - val_acc: 0.9019\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1463 - acc: 0.9445 - val_loss: 0.4263 - val_acc: 0.8982\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2170 - acc: 0.9342 - val_loss: 0.4378 - val_acc: 0.8911\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1533 - acc: 0.9423 - val_loss: 0.3809 - val_acc: 0.9141\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1326 - acc: 0.9474 - val_loss: 0.3374 - val_acc: 0.9114\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1449 - acc: 0.9472 - val_loss: 0.4283 - val_acc: 0.8806\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1423 - acc: 0.9472 - val_loss: 0.2836 - val_acc: 0.9274\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1392 - acc: 0.9457 - val_loss: 0.3829 - val_acc: 0.9152\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1311 - acc: 0.9491 - val_loss: 0.3782 - val_acc: 0.9019\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1375 - acc: 0.9494 - val_loss: 0.3970 - val_acc: 0.9182\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1457 - acc: 0.9472 - val_loss: 0.3444 - val_acc: 0.9253\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1311 - acc: 0.9487 - val_loss: 0.5974 - val_acc: 0.8907\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1453 - acc: 0.9478 - val_loss: 0.4504 - val_acc: 0.9114\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1301 - acc: 0.9486 - val_loss: 0.4626 - val_acc: 0.9138\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1803 - acc: 0.9344 - val_loss: 0.5298 - val_acc: 0.9070\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1274 - acc: 0.9502 - val_loss: 0.5713 - val_acc: 0.9074\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1249 - acc: 0.9518 - val_loss: 0.4973 - val_acc: 0.9104\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 90s 12ms/step - loss: 0.1633 - acc: 0.9442 - val_loss: 0.4259 - val_acc: 0.9009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafdbbdff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7la4f6MtgZo_",
        "colab_type": "code",
        "outputId": "ee0bf95b-bc7d-40cd-e64a-d2a816c0dfa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"===================================================================\")\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 508        1  ...                   0                 3\n",
            "SITTING                  0      415  ...                   0                 0\n",
            "STANDING                 0      104  ...                   0                 0\n",
            "WALKING                  0        3  ...                  25                 0\n",
            "WALKING_DOWNSTAIRS       0        4  ...                 401                 9\n",
            "WALKING_UPSTAIRS         0       25  ...                   1               436\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 4s 1ms/step\n",
            "===================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4257095748275667, 0.9009161859518154]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAEPOiIjAHFL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6ZgtYqPdKIA",
        "colab_type": "code",
        "outputId": "1e78272d-1a4e-46af-ae36-44a4c23214f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(32, input_shape=(timesteps, input_dim),return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 128, 32)           5376      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 13,894\n",
            "Trainable params: 13,894\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8emZrcfafX0w",
        "colab_type": "code",
        "outputId": "60906b2c-59b6-4870-f77d-7c8679d076ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 64s 9ms/step - loss: 1.3137 - acc: 0.4412 - val_loss: 1.2738 - val_acc: 0.4364\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.9880 - acc: 0.5638 - val_loss: 0.8160 - val_acc: 0.5918\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.8551 - acc: 0.5989 - val_loss: 0.7576 - val_acc: 0.5948\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.0227 - acc: 0.5306 - val_loss: 1.3627 - val_acc: 0.3763\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.3331 - acc: 0.4068 - val_loss: 1.3900 - val_acc: 0.3414\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 1.2472 - acc: 0.4066 - val_loss: 1.0449 - val_acc: 0.4869\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.9513 - acc: 0.5238 - val_loss: 0.9030 - val_acc: 0.5219\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 63s 9ms/step - loss: 0.8663 - acc: 0.5253 - val_loss: 1.5402 - val_acc: 0.3672\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 63s 9ms/step - loss: 0.8460 - acc: 0.5344 - val_loss: 0.8111 - val_acc: 0.5199\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7666 - acc: 0.5467 - val_loss: 0.8495 - val_acc: 0.5144\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7616 - acc: 0.5460 - val_loss: 0.8275 - val_acc: 0.5232\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7490 - acc: 0.5501 - val_loss: 0.7960 - val_acc: 0.5378\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.7701 - acc: 0.5686 - val_loss: 0.8114 - val_acc: 0.5226\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.7489 - acc: 0.5975 - val_loss: 0.7196 - val_acc: 0.5887\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.6546 - acc: 0.6753 - val_loss: 0.7327 - val_acc: 0.7401\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.4847 - acc: 0.8016 - val_loss: 0.4940 - val_acc: 0.8215\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.4032 - acc: 0.8619 - val_loss: 0.3677 - val_acc: 0.8734\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.3728 - acc: 0.8826 - val_loss: 0.5609 - val_acc: 0.8534\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2873 - acc: 0.9232 - val_loss: 0.3690 - val_acc: 0.8968\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.2580 - acc: 0.9242 - val_loss: 0.4459 - val_acc: 0.8775\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 59s 8ms/step - loss: 0.2046 - acc: 0.9391 - val_loss: 0.3903 - val_acc: 0.8860\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2009 - acc: 0.9370 - val_loss: 0.3538 - val_acc: 0.9019\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1752 - acc: 0.9426 - val_loss: 0.3524 - val_acc: 0.9108\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1577 - acc: 0.9450 - val_loss: 0.3746 - val_acc: 0.8989\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1644 - acc: 0.9400 - val_loss: 0.2648 - val_acc: 0.9125\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1676 - acc: 0.9427 - val_loss: 0.3381 - val_acc: 0.9128\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1737 - acc: 0.9400 - val_loss: 0.3293 - val_acc: 0.9101\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1453 - acc: 0.9463 - val_loss: 0.2998 - val_acc: 0.9155\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1708 - acc: 0.9400 - val_loss: 0.5825 - val_acc: 0.8690\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2132 - acc: 0.9313 - val_loss: 0.3304 - val_acc: 0.9033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75a83a8d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LFEc1AggbfF",
        "colab_type": "code",
        "outputId": "1b4ddd69-ac84-4fd4-f4f2-6fd2bf4dcbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"===================================================================\")\n",
        "score"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 537        0  ...                   0                 0\n",
            "SITTING                  5      414  ...                   1                 6\n",
            "STANDING                 0      117  ...                   0                10\n",
            "WALKING                  0        0  ...                  29                 3\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 417                 2\n",
            "WALKING_UPSTAIRS         0        0  ...                   7               433\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "2947/2947 [==============================] - 2s 675us/step\n",
            "===================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.330357293030449, 0.9032914828639295]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGwUu2OoAKRt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrnpfOocdKOk",
        "colab_type": "code",
        "outputId": "be7dc941-88cc-46b7-8dfb-ab53238c8708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(128, input_shape=(timesteps, input_dim),return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_12 (LSTM)               (None, 128, 128)          70656     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 120,454\n",
            "Trainable params: 120,454\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gfQUV3XfYi5",
        "colab_type": "code",
        "outputId": "9e780002-a83b-4d30-f6a5-60daedf3856d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,batch_size=batch_size,validation_data=(X_test, Y_test),epochs=epochs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 105s 14ms/step - loss: 1.2247 - acc: 0.4691 - val_loss: 1.7625 - val_acc: 0.1649\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 1.4690 - acc: 0.3660 - val_loss: 1.3499 - val_acc: 0.3977\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 1.3138 - acc: 0.4331 - val_loss: 1.4018 - val_acc: 0.3573\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 1.3620 - acc: 0.3928 - val_loss: 1.4978 - val_acc: 0.2986\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 103s 14ms/step - loss: 1.3831 - acc: 0.3686 - val_loss: 1.3716 - val_acc: 0.3573\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 103s 14ms/step - loss: 1.3121 - acc: 0.4225 - val_loss: 1.3491 - val_acc: 0.3984\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 102s 14ms/step - loss: 1.2424 - acc: 0.4434 - val_loss: 1.3086 - val_acc: 0.4435\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 105s 14ms/step - loss: 1.2227 - acc: 0.4684 - val_loss: 1.3803 - val_acc: 0.3529\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 103s 14ms/step - loss: 1.3627 - acc: 0.3819 - val_loss: 1.2717 - val_acc: 0.4377\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 103s 14ms/step - loss: 1.2796 - acc: 0.4385 - val_loss: 1.2750 - val_acc: 0.3950\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 103s 14ms/step - loss: 1.3694 - acc: 0.4301 - val_loss: 1.1841 - val_acc: 0.4903\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 102s 14ms/step - loss: 1.2529 - acc: 0.4347 - val_loss: 1.3281 - val_acc: 0.4194\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 102s 14ms/step - loss: 1.2814 - acc: 0.4294 - val_loss: 1.2099 - val_acc: 0.4788\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 102s 14ms/step - loss: 1.2272 - acc: 0.4682 - val_loss: 1.2002 - val_acc: 0.4625\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 1.2409 - acc: 0.4353 - val_loss: 1.4531 - val_acc: 0.3488\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 99s 14ms/step - loss: 1.3807 - acc: 0.3670 - val_loss: 1.3847 - val_acc: 0.3658\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 1.3584 - acc: 0.3755 - val_loss: 1.3666 - val_acc: 0.3638\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 1.3562 - acc: 0.3726 - val_loss: 1.3608 - val_acc: 0.3638\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 1.3385 - acc: 0.3870 - val_loss: 1.3439 - val_acc: 0.3767\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 1.3234 - acc: 0.3904 - val_loss: 1.3467 - val_acc: 0.3746\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 99s 14ms/step - loss: 1.3266 - acc: 0.3870 - val_loss: 1.3526 - val_acc: 0.3780\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 99s 13ms/step - loss: 1.3141 - acc: 0.3897 - val_loss: 1.3563 - val_acc: 0.3648\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 1.3725 - acc: 0.3599 - val_loss: 1.3434 - val_acc: 0.3427\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 1.3412 - acc: 0.3757 - val_loss: 1.3390 - val_acc: 0.3678\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 1.1659 - acc: 0.4191 - val_loss: 1.1002 - val_acc: 0.3750\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 0.9099 - acc: 0.5170 - val_loss: 0.9367 - val_acc: 0.4941\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 0.8598 - acc: 0.5284 - val_loss: 0.9397 - val_acc: 0.4394\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 102s 14ms/step - loss: 0.8766 - acc: 0.5254 - val_loss: 0.9051 - val_acc: 0.5300\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 101s 14ms/step - loss: 0.8425 - acc: 0.5354 - val_loss: 0.8619 - val_acc: 0.5124\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 100s 14ms/step - loss: 0.7815 - acc: 0.5721 - val_loss: 0.8343 - val_acc: 0.5823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75a7704048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU5eJqwKdKSj",
        "colab_type": "code",
        "outputId": "06a6252a-d926-4892-ab69-4a110ddefb42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print(\"===================================================================\")\n",
        "score"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  STANDING  WALKING\n",
            "True                                                  \n",
            "LAYING                 493        0        27       17\n",
            "SITTING                  0      243       248        0\n",
            "STANDING                 0       20       508        4\n",
            "WALKING                  0        0        24      472\n",
            "WALKING_DOWNSTAIRS       0        0         4      416\n",
            "WALKING_UPSTAIRS         0        0         8      463\n",
            "2947/2947 [==============================] - 4s 1ms/step\n",
            "===================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8343164877119734, 0.5822870715982355]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYNE7FiWdKWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a8f48410-ddde-45ac-ffd2-b73179490301"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "    \n",
        "x = PrettyTable()\n",
        "\n",
        "x.field_names = [\" # hidden layers\",\"# neurons\", \"loss\", \"Accuracy\"]\n",
        "\n",
        "x.add_row([1,32 , 0.4753, 0.9039 ])\n",
        "x.add_row([1,128 , 0.4440, 0.8768 ])\n",
        "x.add_row([1,64, 0.4244, 0.8941])\n",
        "x.add_row([1,200, 0.4257, 0.9009])\n",
        "x.add_row([2,\"first lstm layer =32, second layer = 32\", 0.3303, 0.9032])\n",
        "x.add_row([2,\"first lstm layer =128, second layer = 64\", 0.8343, 0.5822])\n",
        "\n",
        "print(x)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+------------------------------------------+--------+----------+\n",
            "|  # hidden layers |                # neurons                 |  loss  | Accuracy |\n",
            "+------------------+------------------------------------------+--------+----------+\n",
            "|        1         |                    32                    | 0.4753 |  0.9039  |\n",
            "|        1         |                   128                    | 0.444  |  0.8768  |\n",
            "|        1         |                    64                    | 0.4244 |  0.8941  |\n",
            "|        1         |                   200                    | 0.4257 |  0.9009  |\n",
            "|        2         | first lstm layer =32, second layer = 32  | 0.3303 |  0.9032  |\n",
            "|        2         | first lstm layer =128, second layer = 64 | 0.8343 |  0.5822  |\n",
            "+------------------+------------------------------------------+--------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOOVbPGnzWtl",
        "colab_type": "text"
      },
      "source": [
        "Conclusion:\n",
        "- Running into the problem of exploding gradients while using relu or tanh as activation function \n",
        "- Best scores are for 2 lstm layer architecture with each layer containing 32 neurons and 2 layers of dropout\n",
        "-As we increase number of neurons in 2 lstm layer architecture, performance tends to reduce\n",
        "-Most of the single lstm layer network gave comparable results when used dropouts"
      ]
    }
  ]
}